{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 라이브러리 호출\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_segment_data(filepaths):\n",
    "    segment_data = {}\n",
    "    for filepath in filepaths:\n",
    "        npz_file = np.load(filepath, allow_pickle=True)\n",
    "        for key in npz_file.files:\n",
    "            normalized_key = os.path.basename(key)  # 파일 이름만 추출하여 키로 사용\n",
    "            segment_data[normalized_key] = filepath  \n",
    "    return segment_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_segment_data(filepath, filename):\n",
    "    npz_file = np.load(filepath, allow_pickle=True)\n",
    "    return npz_file[filename]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_paths = {\n",
    "    'anger': [\n",
    "        'segmentation/train/train_anger.npz',\n",
    "        'segmentation/val/val_anger.npz'\n",
    "    ],\n",
    "    'happy': [\n",
    "        'segmentation/train/train_happy.npz',\n",
    "        'segmentation/val/val_happy.npz'\n",
    "    ],\n",
    "    'panic': [\n",
    "        'segmentation/train/train_panic.npz',\n",
    "        'segmentation/val/val_panic.npz'\n",
    "    ],\n",
    "    'sadness': [\n",
    "        'segmentation/train/train_sadness.npz',\n",
    "        'segmentation/val/val_sadness.npz'\n",
    "    ]\n",
    "}\n",
    "\n",
    "segment_data = {emotion: load_segment_data(paths) for emotion, paths in segment_paths.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMG_PATH = 'img/img/train/'\n",
    "VALID_IMG_PATH = 'img/img/val/'\n",
    "\n",
    "TRAIN_JSON_PATH = 'label/train/'\n",
    "VALID_JSON_PATH = 'label/val/'\n",
    "\n",
    "OUTPUT_PATH = 'test_img/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_labels(json_path):\n",
    "    with open(json_path, \"r\", encoding='euc-kr') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_label_data = {\n",
    "    'anger': load_labels(TRAIN_JSON_PATH + \"train_anger.json\"),\n",
    "    'happy': load_labels(TRAIN_JSON_PATH + \"train_happy.json\"),\n",
    "    'panic': load_labels(TRAIN_JSON_PATH + \"train_panic.json\"),\n",
    "    'sadness': load_labels(TRAIN_JSON_PATH + \"train_sadness.json\")\n",
    "}\n",
    "\n",
    "valid_label_data = {\n",
    "    'anger': load_labels(VALID_JSON_PATH + \"val_anger.json\"),\n",
    "    'happy': load_labels(VALID_JSON_PATH + \"val_happy.json\"),\n",
    "    'panic': load_labels(VALID_JSON_PATH + \"val_panic.json\"),\n",
    "    'sadness': load_labels(VALID_JSON_PATH + \"val_sadness.json\")\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_img(filename, path, segment):\n",
    "    image_path = os.path.join(path, filename)\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    new_img = image.copy()\n",
    "    # 이미지 face 만 남기고 나머지는 가림\n",
    "    new_img[segment == 0] = 0\n",
    "    new_img[segment == 1] = 0\n",
    "    new_img[segment == 2] = 0\n",
    "    new_img[segment == 4] = 0\n",
    "    new_img[segment == 5] = 0\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face(label_data, img):\n",
    "\n",
    "  boxes = [label_data['annot_A']['boxes'], label_data['annot_B']['boxes'], label_data['annot_C']['boxes']]\n",
    "  avg_box = { # annot_A/B/C 각 좌표의 평균 값 구해서 저장\n",
    "      'maxX': np.mean([box['maxX'] for box in boxes]),\n",
    "      'maxY': np.mean([box['maxY'] for box in boxes]),\n",
    "      'minX': np.mean([box['minX'] for box in boxes]),\n",
    "      'minY': np.mean([box['minY'] for box in boxes])\n",
    "  }\n",
    "\n",
    "  new_image = img[int(avg_box['minY']):int(avg_box['maxY']), int(avg_box['minX']):int(avg_box['maxX'])] # 평균값으로 이미지 crop\n",
    "\n",
    "  return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_label_data(filename, label_data):\n",
    "    for item in label_data:\n",
    "        if item['filename'] == filename:\n",
    "            return item\n",
    "    return None\n",
    "\n",
    "# 이미지 처리 함수\n",
    "def process_images(emotion, input_folder, output_folder, segment_data, label_data):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(('.jpg', '.png', '.jpeg')):\n",
    "                filename = os.path.basename(file)\n",
    "                filepath = segment_data.get(filename)\n",
    "                if filepath is None:\n",
    "                    continue\n",
    "\n",
    "                segment = get_segment_data(filepath, filename)\n",
    "                \n",
    "                json_data = find_label_data(filename, label_data)\n",
    "                if json_data is None:\n",
    "                    continue\n",
    "\n",
    "                masked_img = mask_img(filename, input_folder, segment)\n",
    "                if masked_img is None:\n",
    "                    continue\n",
    "\n",
    "                cropped_img = crop_face(json_data, masked_img)\n",
    "                if cropped_img is None:\n",
    "                    continue\n",
    "\n",
    "                output_path = os.path.join(output_folder, emotion)\n",
    "                if not os.path.exists(output_path):\n",
    "                    os.makedirs(output_path)\n",
    "\n",
    "                output_file_path = os.path.join(output_path, filename)\n",
    "                if cropped_img.size > 0:\n",
    "                    cv2.imwrite(output_file_path, cv2.cvtColor(cropped_img, cv2.COLOR_RGB2BGR))\n",
    "                else:\n",
    "                    print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n",
      "Error\n"
     ]
    }
   ],
   "source": [
    "for emotion in segment_data.keys():\n",
    "    train_input_folder = os.path.join(TRAIN_IMG_PATH, emotion)\n",
    "    valid_input_folder = os.path.join(VALID_IMG_PATH, emotion)\n",
    "    train_output_folder = os.path.join(OUTPUT_PATH, 'train', emotion)\n",
    "    valid_output_folder = os.path.join(OUTPUT_PATH, 'val', emotion)\n",
    "\n",
    "    process_images(emotion, train_input_folder, train_output_folder, segment_data[emotion], train_label_data[emotion])\n",
    "    process_images(emotion, valid_input_folder, valid_output_folder, segment_data[emotion], valid_label_data[emotion])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
