{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.models as models\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "31f57c013d751f05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ImageTransform() :\n",
    "    def __init__(self, resize, mean, std) :\n",
    "        self.data_transform = {\n",
    "            'train' : transforms.Compose([\n",
    "                transforms.RandomResizedCrop(resize, scale=(0.5, 1.0)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ]),\n",
    "            'val' : transforms.Compose([\n",
    "                transforms.Resize(256),\n",
    "                transforms.CenterCrop(resize),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean, std)\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase) :\n",
    "        return self.data_transform[phase](img)\n"
   ],
   "id": "f5b5a31540a7128f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# define variables\n",
    "size = 224\n",
    "mean = (0.485, 0.456, 0.456)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "batch_size = 32"
   ],
   "id": "9366b42ccfb1689a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "anger_dir = r'./Data/img/train/anger'\n",
    "happy_dir = r'./Data/img/train/happy'\n",
    "panic_dir = r'./Data/img/train/panic'\n",
    "sadness_dir = r'./Data/img/train/sadness'\n",
    "\n",
    "anger_images_filepaths = sorted([os.path.join(anger_dir, f) for f in os.listdir(anger_dir)])\n",
    "happy_images_filepaths = sorted([os.path.join(happy_dir, f) for f in os.listdir(happy_dir)])\n",
    "panic_images_filepaths = sorted([os.path.join(panic_dir, f) for f in os.listdir(panic_dir)])\n",
    "sadness_images_filepaths = sorted([os.path.join(sadness_dir, f) for f in os.listdir(sadness_dir)])\n",
    "\n",
    "image_filepaths = [*anger_images_filepaths, *happy_images_filepaths, *panic_images_filepaths, *sadness_images_filepaths]\n",
    "correct_images_filepaths = [i for i in image_filepaths if cv2.imread(i) is not None]\n",
    "random.seed(42)\n",
    "random.shuffle(correct_images_filepaths)\n",
    "\n",
    "train_images_filepaths = correct_images_filepaths[:400]\n",
    "val_images_filepaths = correct_images_filepaths[400:-10]\n",
    "test_images_filepaths = correct_images_filepaths[-10:]\n",
    "print(len(train_images_filepaths), len(val_images_filepaths), len(test_images_filepaths))\n"
   ],
   "id": "dcefc411fab00524"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class EmotionDataset(Dataset) :\n",
    "    def __init__(self, file_list, transform=None, phase='train') :\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.phase = phase\n",
    "\n",
    "    def __len__(self) :\n",
    "        return len(self.file_list)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx) :\n",
    "        img_path = self.file_list[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img_transformed = self.transform(img, self.phase)\n",
    "\n",
    "        label = img_path.split('/')[-1].split('.')[0]\n",
    "        if label == 'anger' :\n",
    "            label = 0\n",
    "\n",
    "        elif label == 'happy' :\n",
    "            label = 1\n",
    "            \n",
    "        elif label == 'panic' :\n",
    "            label = 2\n",
    "        \n",
    "        elif label == 'sadness' :\n",
    "            label = 3\n",
    "\n",
    "        return img_transformed, label\n"
   ],
   "id": "f0c0121efd3e1024"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_dataset = DogvsCatDataset(train_images_filepaths, transform=ImageTransform(size, mean, std),\n",
    "                                phase='train')\n",
    "val_dataset = DogvsCatDataset(val_images_filepaths, transform=ImageTransform(size, mean, std),\n",
    "                              phase='val')\n",
    "index = 0\n",
    "print(train_dataset.__getitem__(index)[0].size())\n",
    "print(train_dataset.__getitem__(index)[1])\n"
   ],
   "id": "f1e1c17e078e3f2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# load data to memory\n",
    "train_iterator = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_iterator = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "dataloader_dict = {'train' : train_iterator, 'val' : valid_iterator}\n",
    "\n",
    "batch_iterator = iter(train_iterator)\n",
    "inputs, label = next(batch_iterator)\n",
    "print(inputs.size())\n",
    "print(label)\n"
   ],
   "id": "78c4795f1e6ad484"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class BasicBlock(nn.Module) :\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=False) :\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3,\n",
    "                               stride=stirde, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if downsample : # 다운샘플이 적용되는 부분(출력 데이터크기가 다를 경우 사용)\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                             stride=stride, bias=False)\n",
    "\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "\n",
    "        else :\n",
    "            downsample = None\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x) :\n",
    "        i = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        if self.downsample is not None :\n",
    "            i = self.downsample(i)\n",
    "\n",
    "        x += i # identity mapping\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "        \n"
   ],
   "id": "d2bea8ee59952316"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Bottleneck(nn.Module) :\n",
    "    expansion = 4 # 병목 블록을 정의하기 위한 하이퍼파라미터\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=False) :\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1,\n",
    "                               stride=1, bias=False) # 1x1 합성곱층\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels,\n",
    "                               kernel_size=1, stride=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion*out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        if downsample :\n",
    "            conv = nn.Conv2d(in_channels, self.expansion*out_channels, kernel_size=1,\n",
    "                             stride=stride, bias=False)\n",
    "            bn = nn.BatchNorm2d(self.expansion*out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else :\n",
    "            downsample = None\n",
    "\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x) :\n",
    "        i = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.downsample is not None :\n",
    "            i = self.downsample(i)\n",
    "\n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n"
   ],
   "id": "b49b3069970410de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ResNet(nn.Module) :\n",
    "    def __init__(self, config, output_dim, zero_init_residual=False) :\n",
    "        super().__init__()\n",
    "\n",
    "        block, n_blocks, channels = config\n",
    "        self.in_channels = channels[0]\n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2,\n",
    "                               padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride=2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[1], channels[2], stride=2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[1], channels[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "\n",
    "\n",
    "        if zero_init_residual :\n",
    "            for m in self.modules() :\n",
    "                if isinstance(m, BottleNeck) :\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock) :\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "\n",
    "    def get_resnet_layer(self, block, n_blocks, channels, stride=1) :\n",
    "        layers = []\n",
    "        if self.in_channels != block.expansion * channels :\n",
    "            downsample = True\n",
    "        else :\n",
    "            downsample = False\n",
    "\n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "\n",
    "        for i in range(1, n_blocks) :\n",
    "            layers.append(block(block.expansion*channels, channels))\n",
    "\n",
    "        self.in_channels = block.expansion * channels\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.fc(h)\n",
    "        return x, h\n",
    "\n",
    "```python\n",
    "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])\n"
   ],
   "id": "30431a69d15d8ffd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 기본\n",
    "resnet18_config = ResNetConfig(block=BasicBlock,\n",
    "                               n_blocks=[2, 2, 2, 2,],\n",
    "                               channels=[64, 128, 256, 512])\n",
    "\n",
    "resnet34_config = ResNetConfig(block=BasicBlock,\n",
    "                               n_blocks=[3, 4, 6, 3,],\n",
    "                               channels=[64, 128, 256, 512])\n"
   ],
   "id": "a4584410a4cbcbd5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 병목\n",
    "resnet50_config = ResNetConfig(block=Bottleneck,\n",
    "                               n_blocks=[3, 4, 6, 3],\n",
    "                               channels=[64,128,256,512])\n",
    "\n",
    "resnet101_config = ResNetConfig(block=Bottleneck,\n",
    "                                n_blocks=[3,4,23,3],\n",
    "                                channels=[64,128,256,512])\n",
    "\n",
    "resnet152_config = ResNetConfig(block=Bottleneck,\n",
    "                                n_blocks=[3,8,36,3],\n",
    "                                channels=[64,128,256,512])\n"
   ],
   "id": "e550d580495d5303"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "pretrained_model = models.resnet50(pretrained=True)\n",
    "print(pretrained_model)\n"
   ],
   "id": "ad16e78134ba2f44"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "output_dim = 2\n",
    "model = ResNet(resnet50_config, output_dim)\n",
    "print(model)\n"
   ],
   "id": "e38e61d5719eb593"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 손실함수 정의\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-7)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n"
   ],
   "id": "2269fdaa691c65fd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def calculate_topk_accuracy(y_pred, y, k=2) :\n",
    "    with torch.no_grad() :\n",
    "        batch_size = y.shape[0]\n",
    "        _, top_pred = y_pred.topk(k, 1)\n",
    "        top_pred = top_pred.t()\n",
    "        correct = top_pred.eq(y.view(1, -1).expand_as(top_pred))\n",
    "        correct_1 = correct[:1].reshape(-1).float().sum(0, keepdim=True)\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "        acc_1 = correct_1 / batch_size\n",
    "        acc_k = correct_k / batch_size\n",
    "\n",
    "    return acc_1, acc_k\n"
   ],
   "id": "40ab3cb0a8ba3ef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(model, iterator, optimizer, criterion, device) :\n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "    model.train()\n",
    "    for (x, y) in iterator :\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = criterion(y_pred[0], y)\n",
    "\n",
    "        acc_1, acc_5 = calculate_topk_accuracy(y_pred[0], y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc_1 += acc_1.item()\n",
    "        epoch_acc_5 += acc_5.item()\n",
    "\n",
    "    epoch_loss /= len(iterator)\n",
    "    epoch_acc_1 /= len(iterator)\n",
    "    epoch_acc_5 /= len(iterator)\n",
    "\n",
    "    return epoch_loss, epoch_acc_1, epoch_acc_5\n"
   ],
   "id": "cf836fbeed03baf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def evaluate(model, iterator, criterion, device) :\n",
    "    epoch_loss = 0\n",
    "    epoch_acc_1 = 0\n",
    "    epoch_acc_5 = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad() :\n",
    "        for (x, y) in iterator :\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred[0], y)\n",
    "\n",
    "            acc_1, acc_5 = calculate_topk_accuracy(y_pred[0], y)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc_1 += acc_1.item()\n",
    "            epoch_acc_5 += acc_5.item()\n",
    "\n",
    "        epoch_loss /=len(iterator)\n",
    "        epoch_acc_1 /= len(iterator)\n",
    "        epoch_acc_5 /= len(iterator)\n",
    "\n",
    "        return epoch_loss, epoch_acc_1, epoch_acc_5\n"
   ],
   "id": "94be95b64eb428ab"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def epoch_time(start_time, end_time) :\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n"
   ],
   "id": "5b4a466d0aa84f14"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "best_valid_loss = float('inf')\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs) :\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    train_loss, train_acc_1, train_acc_5 = train(model, train_iterator, optimizer,\n",
    "                                                 criterion, device)\n",
    "    valid_loss, valid_acc_1, valid_acc_5 = evaluate(model, valid_iterator, criterion,\n",
    "                                                    device)\n",
    "\n",
    "    if valid_loss < best_valid_loss :\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '../080289-main/chap06/data/ResNet-model.pt')\n",
    "\n",
    "    end_time = time.monotonic()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch : {epoch+1:02} | Epoch Time : {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss : {train_loss:.3f} | Train Acc @1 : {train_acc_1*100:6.2f}% | Train Acc @5 : {train_acc_5*100:6.2f}%')\n",
    "    print(f'\\tValid Loss : {valid_loss:.3f} | Valid Acc @1 : {valid_acc_1*100:6.2f}% | Valid Acc @5 : {valid_acc_5*100:6.2f}%')    \n"
   ],
   "id": "f719c16446d1989f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "id_list = []\n",
    "pred_list = []\n",
    "_id = 0\n",
    "\n",
    "with torch.no_grad() :\n",
    "    for test_path in test_images_filepaths :\n",
    "        img = Image.open(test_path)\n",
    "        _id = test_path.split('/')[-1].split('.')[1]\n",
    "        transform = ImageTransform(size, mean, std)\n",
    "        img = transform(img, phase='val')\n",
    "        img = img.unsqueeze(0)\n",
    "        img = img.to(device)\n",
    "\n",
    "        model.eval()\n",
    "        outputs = model(img)\n",
    "        preds = F.softmax(outputs[0], dim=1)[:, 1].tolist()\n",
    "        id_list.append(_id)\n",
    "        pred_list.append(preds[0])\n",
    "\n",
    "res = pd.DataFrame({\n",
    "    'id' : id_list,\n",
    "    'label' : pred_list\n",
    "})\n",
    "\n",
    "res.sort_values(by='id', inplace=True)\n",
    "res.reset_index(drop=True, inplace=True)\n",
    "\n",
    "res.to_csv('../080289-main/chap06/data/ResNet.csv', index=False)\n",
    "res.head(10)\n"
   ],
   "id": "fc8855d5b40b5c7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "id_list = []\n",
    "pred_list = []\n",
    "_id = 0\n",
    "\n",
    "with torch.no_grad() :\n",
    "    for test_path in test_images_filepaths :\n",
    "        img = Image.open(test_path)\n",
    "        _id = test_path.split('/')[-1].split('.')[1]\n",
    "        transform = ImageTransform(size, mean, std)\n",
    "        img = transform(img, phase='val')\n",
    "        img = img.unsqueeze(0)\n",
    "        img = img.to(device)\n",
    "\n",
    "        model.eval()\n",
    "        outputs = model(img)\n",
    "        preds = F.softmax(outputs[0], dim=1)[:, 1].tolist()\n",
    "        id_list.append(_id)\n",
    "        pred_list.append(preds[0])\n",
    "\n",
    "res = pd.DataFrame({\n",
    "    'id' : id_list,\n",
    "    'label' : pred_list\n",
    "})\n",
    "\n",
    "res.sort_values(by='id', inplace=True)\n",
    "res.reset_index(drop=True, inplace=True)\n",
    "\n",
    "res.to_csv('../080289-main/chap06/data/ResNet.csv', index=False)\n",
    "res.head(10)\n",
    "class_ = classes = {0 : 'cat', 1 : 'dog'}\n",
    "\n",
    "def display_image_grid(images_filepaths, predicted_labels=(), cols=5) :\n",
    "    rows = len(images_filepaths) // cols\n",
    "    fig , ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 6))\n",
    "    for i, image_filepath in enumerate(images_filepaths) :\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        a = random.choice(res['id'].values)\n",
    "        label = res.loc[res['id'] == a, 'label'].values[0]\n",
    "\n",
    "        if label > 0.5 :\n",
    "            label = 1\n",
    "        else :\n",
    "            label = 0\n",
    "\n",
    "        ax.ravel()[i].imshow(image)\n",
    "        ax.ravel()[i].set_title(class_[label])\n",
    "        ax.ravel()[i].set_axis_off()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "display_image_grid(test_images_fileapths)\n"
   ],
   "id": "35781bd8211096d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
